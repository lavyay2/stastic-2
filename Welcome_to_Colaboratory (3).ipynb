{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Hypothesis Testing in Statistics\n",
        "\n",
        "Definition: Hypothesis testing is a statistical method used to make inferences about a population based on a sample of data. It involves formulating a null hypothesis (H₀) and an alternative hypothesis (H₁) and then using statistical tests to determine whether to reject or fail to reject the null hypothesis.\n",
        "2. Null Hypothesis (H₀) vs. Alternative Hypothesis (H₁)\n",
        "\n",
        "Null Hypothesis (H₀): A statement of no effect, no difference, or no relationship between variables. It's the default assumption.\n",
        "Alternative Hypothesis (H₁): A statement that contradicts the null hypothesis. It suggests an effect, difference, or relationship.\n",
        "3. Significance Level (α)\n",
        "\n",
        "Definition: The probability of rejecting the null hypothesis when it is actually true.\n",
        "Importance: It controls the risk of making a Type I error. Common significance levels are 0.05 (5%) and 0.01 (1%).\n",
        "4. P-value\n",
        "\n",
        "Definition: The probability of observing the data (or more extreme data) if the null hypothesis were true.\n",
        "Interpretation:\n",
        "If P-value ≤ α, reject the null hypothesis.\n",
        "If P-value > α, fail to reject the null hypothesis.\n",
        "5. Type I and Type II Errors\n",
        "\n",
        "Type I Error: Rejecting the null hypothesis when it is actually true (false positive).\n",
        "Type II Error: Failing to reject the null hypothesis when it is actually false (false negative).\n",
        "6. One-tailed vs. Two-tailed Tests\n",
        "\n",
        "One-tailed Test: Tests for an effect in only one direction (e.g., greater than, less than).\n",
        "Two-tailed Test: Tests for an effect in either direction (e.g., different from).\n",
        "7. Z-test\n",
        "\n",
        "Definition: A statistical test used to compare the mean of a sample to the mean of a known population with a known standard deviation.\n",
        "Usage: When the population standard deviation is known and the sample size is large (usually n ≥ 30).\n",
        "8. Z-score\n",
        "\n",
        "Calculation: (Sample mean - Population mean) / (Population standard deviation / √sample size)\n",
        "Interpretation: Represents the number of standard deviations a sample mean is from the population mean.\n",
        "9. T-distribution\n",
        "\n",
        "Definition: A probability distribution similar to the normal distribution but with heavier tails, used when the population standard deviation is unknown.\n",
        "Usage: When the population standard deviation is unknown and the sample size is small (usually n < 30).\n",
        "10. Z-test vs. T-test\n",
        "\n",
        "Z-test: Uses population standard deviation, suitable for large samples.\n",
        "T-test: Uses sample standard deviation, suitable for small samples.\n",
        "11. T-test\n",
        "\n",
        "Definition: A statistical test used to compare means between groups when the population standard deviation is unknown.\n",
        "Types: One-sample t-test, independent samples t-test, paired samples t-test.\n",
        "12. Relationship between Z-test and T-test\n",
        "\n",
        "As sample size increases, the t-distribution approaches the standard normal distribution (Z-distribution).\n",
        "13. Confidence Interval\n",
        "\n",
        "Definition: A range of values within which the true population parameter is likely to fall with a certain level of confidence.\n",
        "Interpretation: Provides a range of plausible values for the population parameter.\n",
        "14. Margin of Error\n",
        "\n",
        "Definition: The amount by which the sample statistic may differ from the true population parameter.\n",
        "Effect on Confidence Interval: A larger margin of error results in a wider confidence interval.\n",
        "15. Bayes' Theorem\n",
        "\n",
        "Usage: Used to update probabilities based on new evidence.\n",
        "Significance: Provides a framework for probabilistic reasoning and inference.\n",
        "16. Chi-square Distribution\n",
        "\n",
        "Definition: A probability distribution used to test hypotheses about categorical data.\n",
        "Usage: Chi-square goodness-of-fit test, chi-square test for independence.\n",
        "17. Chi-square Goodness-of-fit Test\n",
        "\n",
        "Definition: Tests whether observed frequencies in a categorical variable match expected frequencies.\n",
        "18. F-distribution\n",
        "\n",
        "Definition: A probability distribution used to compare variances between two or more groups.\n",
        "Usage: ANOVA (Analysis of Variance).\n",
        "\n",
        "\n",
        "19.Hypothesis testing is a statistical method used to make inferences about a population based on a sample of data. It involves formulating a null hypothesis (a statement of no relationship or no difference between variables) and an alternative hypothesis and then using data and statistical analysis to determine which hypothesis is more likely to be true.\n",
        "\n",
        "There are several types of hypothesis tests, including:\n",
        "\n",
        "One-Sample Tests: One-Sample hypothesis test is used to compare a sample mean to a population mean. In other words, it is used to determine if the sample mean is significantly different from a specified value (population mean).\n",
        "\n",
        "\n",
        "20. ANOVA (Analysis of Variance)\n",
        "\n",
        "Definition: A statistical method used to compare the means of three or more groups.\n",
        "Types: One-way ANOVA, two-way ANOVA.\n",
        "21. ANOVA Assumptions\n",
        "\n",
        "Normality: The data within each group should be normally distributed.\n",
        "Homogeneity of variances: The variance of the dependent variable should be equal across all groups.\n",
        "Independence: Observations within and between groups should be independent.\n",
        "22. Types of ANOVA Tests\n",
        "\n",
        "One-way ANOVA: Compares means of multiple groups for a single independent variable.\n",
        "Two-way ANOVA: Compares means of multiple groups for two independent variables and their interaction.\n",
        "23. F-test\n",
        "\n",
        "Definition: A statistical test used to compare the variances of two or more groups.\n",
        "Relationship to Hypothesis Testing: In ANOVA, the F-test determines whether there are statistically significant differences between group means.\n"
      ],
      "metadata": {
        "id": "I4lZhIz7TMFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Z-test for Comparing Sample Mean to Population Mean\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 50\n",
        "population_mean = 48\n",
        "population_std = 10\n",
        "sample_size = 50\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / (sample_size ** 0.5))\n",
        "\n",
        "# Calculate p-value\n",
        "p_value = stats.norm.sf(abs(z_score)) * 2  # Two-tailed test\n",
        "\n",
        "print(\"Z-score:\", z_score)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. Sample mean is significantly different from population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. Sample mean is not significantly different from population mean.\")\n",
        "2. Simulate Data and Perform Hypothesis Testing\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate data from a normal distribution\n",
        "population_mean = 50\n",
        "population_std = 10\n",
        "sample_size = 30\n",
        "data = np.random.normal(loc=population_mean, scale=population_std, size=sample_size)\n",
        "\n",
        "# Perform t-test (since population standard deviation is unknown)\n",
        "t_stat, p_value = stats.ttest_1samp(data, population_mean)\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. Sample mean is significantly different from population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. Sample mean is not significantly different from population mean.\")\n",
        "3. One-sample Z-test\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 50\n",
        "population_mean = 48\n",
        "population_std = 10\n",
        "sample_size = 50\n",
        "\n",
        "# Perform Z-test\n",
        "z_stat, p_value = stats.zscore(sample_mean, a=population_mean, ddof=0), stats.norm.sf(abs(z_stat))*2\n",
        "\n",
        "print(\"Z-statistic:\", z_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. Sample mean is significantly different from population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. Sample mean is not significantly different from population mean.\")\n",
        "4. Two-tailed Z-test with Visualization\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 50\n",
        "population_mean = 48\n",
        "population_std = 10\n",
        "sample_size = 50\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / (sample_size ** 0.5))\n",
        "\n",
        "# Calculate p-value\n",
        "p_value = stats.norm.sf(abs(z_score)) * 2  # Two-tailed test\n",
        "\n",
        "# Visualize\n",
        "x = np.linspace(-4, 4, 100)\n",
        "plt.plot(x, stats.norm.pdf(x))\n",
        "plt.axvline(x=z_score, color='red', linestyle='--')\n",
        "plt.axvline(x=-z_score, color='red', linestyle='--')\n",
        "plt.fill_between(x[x > abs(z_score)], 0, stats.norm.pdf(x[x > abs(z_score)]), alpha=0.2, color='red')\n",
        "plt.fill_between(x[x < -abs(z_score)], 0, stats.norm.pdf(x[x < -abs(z_score)]), alpha=0.2, color='red')\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.title('Two-tailed Z-test')\n",
        "plt.show()\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. Sample mean is significantly different from population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. Sample mean is not significantly different from population mean.\")\n",
        "5. Type I and Type II Error Function\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_type_i_type_ii_errors(alpha, true_mean, sample_mean, population_std, sample_size):\n",
        "    # ... (Visualization code for Type I and Type II errors) ...\n",
        "6. Independent Samples T-test\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data for two groups\n",
        "group1 = [5, 10, 15, 20, 25]\n",
        "group2 = [10, 15, 20, 25, 30]\n",
        "\n",
        "# Perform independent samples t-test\n",
        "t_stat, p_value = stats.ttest_ind(group1, group2)\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference between the means of the two groups.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference between the means of the two groups.\")\n",
        "7. Paired Samples T-test\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data for paired observations\n",
        "before = [10, 12, 15, 18, 20]\n",
        "after = [12, 14, 17, 20, 22]\n",
        "\n",
        "# Perform paired samples t-test\n",
        "t_stat, p_value = stats.ttest_rel(before, after)\n",
        "\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference between the before and after measurements.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference between the before and after measurements.\")\n",
        "8. Z-test vs. T-test Comparison\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Simulate data and perform Z-test and T-test, compare results) ...\n",
        "9. Confidence Interval Calculation\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 50\n",
        "sample_std = 5\n",
        "sample_size = 30\n",
        "confidence_level = 0.95\n",
        "\n",
        "# Calculate margin of error\n",
        "margin_of_error = stats.t.ppf((1 + confidence_level) / 2, df=sample_size - 1) * (sample_std / (sample_size ** 0.5))\n",
        "\n",
        "# Calculate confidence interval\n",
        "lower_bound = sample_mean - margin_of_error\n",
        "upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "print(\"Confidence Interval:\", (lower_bound, upper_bound))\n",
        "10. Margin of Error Calculation\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 50\n",
        "sample_std = 5\n",
        "sample_size = 30\n",
        "confidence_level = 0.95\n",
        "\n",
        "# Calculate margin of error\n",
        "margin_of_error = stats.t.ppf((1 + confidence_level) / 2, df=sample_size - 1) * (sample_std / (sample_size ** 0.5))\n",
        "\n",
        "print(\"Margin of Error:\",\n",
        "\n",
        "\n",
        "\n",
        "      11. Bayesian Inference with PyMC3\n",
        "\n",
        "Python\n",
        "\n",
        "import pymc3 as pm\n",
        "\n",
        "# Define the model\n",
        "with pm.Model() as model:\n",
        "    # Prior distribution for the mean\n",
        "    mu = pm.Normal('mu', mu=50, sigma=10)\n",
        "    # Likelihood (assuming normal distribution)\n",
        "    y_obs = pm.Normal('y_obs', mu=mu, sigma=5, observed=data)\n",
        "\n",
        "    # Sample from the posterior distribution\n",
        "    trace = pm.sample(1000, tune=1000)\n",
        "\n",
        "# Extract posterior samples for the mean\n",
        "posterior_samples = trace['mu']\n",
        "\n",
        "# Analyze posterior distribution (e.g., calculate credible intervals)\n",
        "# ...\n",
        "12. Chi-square Test for Independence\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Observed frequencies in a contingency table\n",
        "observed_freqs = np.array([[10, 20], [30, 15]])\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2_stat, p_value, dof, expected_freqs = stats.chi2_contingency(observed_freqs)\n",
        "\n",
        "print(\"Chi-square statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant association between the two variables.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant association between the two variables.\")\n",
        "13. Chi-square Goodness-of-fit Test\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Observed frequencies\n",
        "observed_freqs = np.array([10, 20, 30, 40])\n",
        "\n",
        "# Expected frequencies under the null hypothesis\n",
        "expected_freqs = np.array([25, 25, 25, 25])\n",
        "\n",
        "# Perform chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = stats.chisquare(observed_freqs, f_exp=expected_freqs)\n",
        "\n",
        "print(\"Chi-square statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. The observed frequencies do not fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The observed frequencies fit the expected distribution.\")\n",
        "14. Simulate and Visualize Chi-square Distribution\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Degrees of freedom\n",
        "df = 5\n",
        "\n",
        "# Generate random samples from chi-square distribution\n",
        "x = np.linspace(0, 20, 100)\n",
        "y = stats.chi2.pdf(x, df)\n",
        "\n",
        "# Plot the chi-square distribution\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('Chi-square')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.title('Chi-square Distribution (df={})'.format(df))\n",
        "plt.show()\n",
        "15. F-test for Comparing Variances\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data for two groups\n",
        "group1 = [5, 10, 15, 20, 25]\n",
        "group2 = [10, 15, 20, 25, 30]\n",
        "\n",
        "# Perform F-test\n",
        "f_stat, p_value = stats.f_oneway(group1, group2)\n",
        "\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. The variances of the two groups are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. The variances of the two groups are not significantly different.\")\n",
        "16. One-way ANOVA\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data for multiple groups\n",
        "group1 = [5, 10, 15, 20, 25]\n",
        "group2 = [10, 15, 20, 25, 30]\n",
        "group3 = [15, 20, 25, 30, 35]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference between the means of the groups.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference between the means of the groups.\")\n",
        "17. Check ANOVA Assumptions\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to check normality, homogeneity of variances, and independence) ...\n",
        "18. Two-way ANOVA\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to perform two-way ANOVA) ...\n",
        "19. Visualize F-distribution\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to simulate and visualize F-distribution) ...\n",
        "20. One-way ANOVA with Boxplots\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to perform one-way ANOVA and create boxplots for visualization) ...\n",
        "21. Simulate Data and Perform Hypothesis Testing\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to simulate data, perform hypothesis testing, and evaluate means) ...\n",
        "22. Hypothesis Test for Population Variance\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to perform hypothesis test for population variance using chi-square distribution) ...\n",
        "23. Z-test for Comparing Proportions\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to perform Z-test for comparing proportions between two datasets or groups) ...\n",
        "24. F-test for Comparing Variances\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to perform F-test for comparing variances of two datasets, interpret and visualize results) ...\n",
        "25. Chi-square Goodness-of-fit Test with Simulated Data\n",
        "\n",
        "Python\n",
        "\n",
        "# ... (Code to perform Chi-square goodness-of-fit test with simulated data and analyze results\n",
        "\n",
        "26. One-way ANOVA with Boxplots\n",
        "\n",
        "Python\n",
        "\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for multiple groups\n",
        "group1 = [5, 10, 15, 20, 25]\n",
        "group2 = [10, 15, 20, 25, 30]\n",
        "group3 = [15, 20, 25, 30, 35]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Create boxplots\n",
        "plt.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'])\n",
        "plt.ylabel('Values')\n",
        "plt.title('Boxplot of Groups')\n",
        "plt.show()\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference between the means of the groups.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference between the means of the groups.\")\n",
        "27. Simulate Data and Perform Hypothesis Testing\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate data from a normal distribution (e.g., for a one-sample t-test)\n",
        "population_mean = 50\n",
        "population_std = 10\n",
        "sample_size = 30\n",
        "data = np.random.normal(loc=population_mean, scale=population_std, size=sample_size)\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = stats.ttest_1samp(data, population_mean)\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. Sample mean is significantly different from population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. Sample mean is not significantly dif"
      ],
      "metadata": {
        "id": "XUVpwwtERz_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QIFMJIHhR0IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZPcTQ8qR0Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcpae1FPR0Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TMWVksjgR0Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxcLX3-qR0cJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}